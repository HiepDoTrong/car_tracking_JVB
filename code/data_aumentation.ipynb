{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "width, height = 1280, 640\n",
    "fps = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# noise\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "# output_path = \"./aumented_video/human_camG/G1_noise.mp4\"\n",
    "# out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# # Add noise to each frame\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "#     # Generate random noise\n",
    "#     noise = np.random.normal(0, 0.5, frame.shape).astype(np.uint8)\n",
    "\n",
    "#     # Add noise to the frame\n",
    "#     noisy_frame = cv2.add(frame, noise)\n",
    "\n",
    "#     # Write the noisy frame to the output video\n",
    "#     out.write(noisy_frame)\n",
    "\n",
    "#     # Display the noisy frame\n",
    "#     cv2.imshow(\"Noisy Video\", noisy_frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and writer\n",
    "# cap.release()\n",
    "# out.release()\n",
    "\n",
    "# # Close all windows\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# blur\n",
    "\n",
    "# Load the video\n",
    "# input video\n",
    "video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_short/human_camD/human_camD.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "# output video\n",
    "out_blur = cv2.VideoWriter(\"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/human_camD/human_camD_blur.mp4\", fourcc, 30, (width, height))\n",
    "# Add blur to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply Gaussian blur to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    # Write the blurred frame to the output video\n",
    "    out_blur.write(blurred_frame)\n",
    "\n",
    "    # Display the blurred frame\n",
    "    cv2.imshow(\"Blurred Video\", blurred_frame)\n",
    "    # cv2.imshow(\"Blurred Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out_blur.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# sharp\n",
    "# Load the video\n",
    "video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_short/human_camD/human_camD.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "# Create a new VideoWriter object for the brightened video\n",
    "out_sharp = cv2.VideoWriter(\"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/human_camD/human_camD_sharp.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# Apply gamma transformation to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply gamma transformation to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_blur = cv2.blur(frame_gray, (5, 5))\n",
    "    diff = cv2.subtract(frame_gray, frame_blur)\n",
    "\n",
    "    b, g, r = cv2.split(frame)\n",
    "    b_final = cv2.addWeighted(b, 0.9, diff, 0.9, 0.0)\n",
    "    g_final = cv2.addWeighted(g, 0.9, diff, 0.9, 0.0)\n",
    "    r_final = cv2.addWeighted(r, 0.9, diff, 0.9, 0.0)\n",
    "    \n",
    "    frame = cv2.merge((b_final, g_final, r_final))\n",
    "    # Write the brightened frame to the output video\n",
    "    out_sharp.write(frame)\n",
    "\n",
    "    # Display the brightened frame\n",
    "    cv2.imshow(\"Brightened Video\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "out_sharp.release()\n",
    "cap.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Bright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bright\n",
    "\n",
    "# Load the video\n",
    "video_path = \"./short_video/camG/camG1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "\n",
    "#increase the gamma value to make the video brighter\n",
    "gamma = 1.5 \n",
    "#decrease the gamma value to make the video darker\n",
    "# gamma = 0.5 \n",
    "\n",
    "# Create a lookup table for gamma transformation\n",
    "gamma_table = np.array([((i / 255) ** (1 / gamma)) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "\n",
    "# Create a new VideoWriter object for the brightened video\n",
    "out_bright = cv2.VideoWriter(\"./aumented_video/camG/G1_bright_increased.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# Apply gamma transformation to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply gamma transformation to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    bright_frame = cv2.LUT(frame, gamma_table)\n",
    "\n",
    "    # Write the brightened frame to the output video\n",
    "    out_bright.write(bright_frame)\n",
    "\n",
    "    # Display the brightened frame\n",
    "    cv2.imshow(\"Brightened Video\", bright_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out_bright.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# contrast\n",
    "\n",
    "# Load the video\n",
    "video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_short/human_camD/human_camD.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "\n",
    "# Create a new VideoWriter object for the contrast-enhanced video\n",
    "out_contrast = cv2.VideoWriter(\"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/human_camD/human_camD_contrast_increased.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# Apply histogram equalization to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply histogram equalization to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    # Convert the frame to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Increase the V channel\n",
    "    v = hsv[:,:,2]\n",
    "    v = cv2.equalizeHist(v)\n",
    "\n",
    "    # Merge channels back\n",
    "    hsv[:,:,2] = v\n",
    "    equalized_frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    out_contrast.write(equalized_frame)\n",
    "\n",
    "    # Display the contrast-enhanced frame\n",
    "    cv2.imshow(\"Contrast-enhanced Video\", equalized_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out_contrast.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rain\n",
    "\n",
    "# Load the rain video\n",
    "rain_video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/overlay_weathers/videoplayback.mp4\"\n",
    "rain_cap = cv2.VideoCapture(rain_video_path)\n",
    "\n",
    "cloud_video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/overlay_weathers/cloud.mp4\"\n",
    "cloud_cap = cv2.VideoCapture(cloud_video_path)\n",
    "\n",
    "# Load your video\n",
    "your_video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_short/human_camD/human_camD.mp4\"\n",
    "your_cap = cv2.VideoCapture(your_video_path)\n",
    "\n",
    "# Define the output video path\n",
    "output_path_rain = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/human_camD/human_camD_rain.mp4\"\n",
    "\n",
    "# Define the codec for the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out_rain = cv2.VideoWriter(output_path_rain, fourcc, fps, (width, height))\n",
    "\n",
    "gamma = 0.5\n",
    "gamma2 = 0.2\n",
    "\n",
    "# Create a lookup table for gamma transformation\n",
    "gamma_table = np.array([((i / 255) ** (1 / gamma)) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "cloud_table = np.array([((i / 255) ** (1 / gamma2)) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "\n",
    "# Add the rain effect to each frame of your video\n",
    "while your_cap.isOpened():\n",
    "    ret, your_frame = your_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Read a frame from the rain video\n",
    "    ret, rain_frame = rain_cap.read()\n",
    "    if not ret:\n",
    "        # Restart the rain video if it reaches the end\n",
    "        rain_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, rain_frame = rain_cap.read()\n",
    "\n",
    "    ret, cloud_frame = cloud_cap.read()\n",
    "    if not ret:\n",
    "        # Restart the rain video if it reaches the end\n",
    "        cloud_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, cloud_frame = cloud_cap.read()\n",
    "\n",
    "    # Resize the rain frame to match the size of your video frame\n",
    "    rain_frame = cv2.resize(rain_frame, (width, height))\n",
    "    your_frame = cv2.resize(your_frame, (width, height))\n",
    "    cloud_frame = cv2.resize(cloud_frame, (width, height))\n",
    "    cloud_frame = cv2.cvtColor(cloud_frame, cv2.COLOR_BGR2GRAY)\n",
    "    cloud_frame = cv2.bitwise_not(cloud_frame)\n",
    "    cloud_frame = cv2.LUT(cloud_frame, cloud_table)\n",
    "\n",
    "\n",
    "    # cloud_frame = 1 - cloud_frame\n",
    "    cloud_frame = cv2.merge([cloud_frame, cloud_frame, cloud_frame])\n",
    "\n",
    "    # Add the rain effect to your video frame\n",
    "    output_frame = cv2.addWeighted(your_frame, 0.9, rain_frame, 0.9, 0)\n",
    "    output_frame = cv2.addWeighted(output_frame, 0.9, cloud_frame, 0.5, 0)\n",
    "\n",
    "    output_frame = cv2.LUT(output_frame, gamma_table)\n",
    "\n",
    "    # Write the output frame to the output video\n",
    "    out_rain.write(output_frame)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Output Video\", output_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video captures and writer\n",
    "your_cap.release()\n",
    "rain_cap.release()\n",
    "out_rain.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sunset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# sunset\n",
    "\n",
    "from skimage import exposure\n",
    "# Load the video\n",
    "video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_short/human_camD/human_camD.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "ref = cv2.imread(\"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/overlay_weathers/sunset_car.jpeg\")\n",
    "ref = cv2.resize(ref, (width, height))\n",
    "# ref = cv2.cvtColor(ref, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create a new VideoWriter object for the contrast-enhanced video\n",
    "out_sunset = cv2.VideoWriter(\"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/human_camD/human_camD_sunset.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "gamma = 0.6\n",
    "#decrease the gamma value to make the video darker\n",
    "# gamma = 0.5 \n",
    "\n",
    "# Create a lookup table for gamma transformation\n",
    "gamma_table = np.array([((i / 255) ** (1 / gamma)) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "\n",
    "# Apply histogram equalization to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply histogram equalization to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    matched = exposure.match_histograms(frame, ref, channel_axis=-1)\n",
    "    matched = matched.astype('uint8')\n",
    "    matched = cv2.LUT(matched, gamma_table)\n",
    "\n",
    "    brightness_reduction_value = 40\n",
    "    # matched = cv2.subtract(matched, brightness_reduction_value)\n",
    "\n",
    "    out_sunset.write(matched)\n",
    "\n",
    "    # Display the contrast-enhanced frame\n",
    "    cv2.imshow(\"Contrast-enhanced Video\", matched)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out_sunset.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharp\n",
    "# Load the video\n",
    "video_path = \"/home/dotronghiep/Documents/JVBCompany/car_tracking_JVB/video_aumented/human_camD/human_camD_sharp.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply gamma transformation to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    \n",
    "    # Display the brightened frame\n",
    "    cv2.imshow(\"Brightened Video\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_track_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
