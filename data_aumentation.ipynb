{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 30.0, Width: 1280, Height: 640\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the video\n",
    "video_path = \"./short_video/camG/camG1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width, height = 1280, 640\n",
    "print(f\"FPS: {fps}, Width: {width}, Height: {height}\")\n",
    "\n",
    "# Define the codec for output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output_path = \"./aumented_video/camG/G1_noise.mp4\"\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Add noise to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "    # Generate random noise\n",
    "    noise = np.random.normal(0, 0.5, frame.shape).astype(np.uint8)\n",
    "\n",
    "    # Add noise to the frame\n",
    "    noisy_frame = cv2.add(frame, noise)\n",
    "\n",
    "    # Write the noisy frame to the output video\n",
    "    out.write(noisy_frame)\n",
    "\n",
    "    # Display the noisy frame\n",
    "    cv2.imshow(\"Noisy Video\", noisy_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# Load the video\n",
    "video_path = \"./short_video/camG/camG1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "out_blur = cv2.VideoWriter(\"./aumented_video/camG/G1_blur.mp4\", fourcc, fps, (width, height))\n",
    "# Add blur to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply Gaussian blur to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    # Write the blurred frame to the output video\n",
    "    out_blur.write(blurred_frame)\n",
    "\n",
    "    # Display the blurred frame\n",
    "    cv2.imshow(\"Blurred Video\", blurred_frame)\n",
    "    # cv2.imshow(\"Blurred Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out_blur.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video_path = \"./short_video/camG/camG1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#increase the gamma value to make the video brighter\n",
    "gamma = 1.5 \n",
    "#decrease the gamma value to make the video darker\n",
    "# gamma = 0.5 \n",
    "\n",
    "# Create a lookup table for gamma transformation\n",
    "gamma_table = np.array([((i / 255) ** (1 / gamma)) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "\n",
    "# Create a new VideoWriter object for the brightened video\n",
    "out_bright = cv2.VideoWriter(\"./aumented_video/camG/G1_bright_increased.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# Apply gamma transformation to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply gamma transformation to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    bright_frame = cv2.LUT(frame, gamma_table)\n",
    "\n",
    "    # Write the brightened frame to the output video\n",
    "    out_bright.write(bright_frame)\n",
    "\n",
    "    # Display the brightened frame\n",
    "    cv2.imshow(\"Brightened Video\", bright_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out_bright.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# Load the video\n",
    "video_path = \"./short_video/camG/camG1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Create a new VideoWriter object for the contrast-enhanced video\n",
    "out_contrast = cv2.VideoWriter(\"./aumented_video/camG/G1_contrast_increased.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# Apply histogram equalization to each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply histogram equalization to the frame\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    # Convert the frame to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Increase the V channel\n",
    "    v = hsv[:,:,2]\n",
    "    v = cv2.equalizeHist(v)\n",
    "\n",
    "    # Merge channels back\n",
    "    hsv[:,:,2] = v\n",
    "    equalized_frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    out_contrast.write(equalized_frame)\n",
    "\n",
    "    # Display the contrast-enhanced frame\n",
    "    cv2.imshow(\"Contrast-enhanced Video\", equalized_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "cap.release()\n",
    "out_contrast.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rain video\n",
    "rain_video_path = \"./aumented_video/overlay_weathers/videoplayback.mp4\"\n",
    "rain_cap = cv2.VideoCapture(rain_video_path)\n",
    "\n",
    "cloud_video_path = \"./aumented_video/overlay_weathers/cloud.mp4\"\n",
    "cloud_cap = cv2.VideoCapture(cloud_video_path)\n",
    "\n",
    "# Load your video\n",
    "your_video_path = \"./short_video/camG/camG1.mp4\"\n",
    "your_cap = cv2.VideoCapture(your_video_path)\n",
    "\n",
    "# Define the output video path\n",
    "output_path_rain = \"./aumented_video/camG/G1_rain.mp4\"\n",
    "\n",
    "# Define the codec for the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out_rain = cv2.VideoWriter(output_path_rain, fourcc, fps, (width, height))\n",
    "\n",
    "gamma = 0.5\n",
    "gamma2 = 0.2\n",
    "\n",
    "# Create a lookup table for gamma transformation\n",
    "gamma_table = np.array([((i / 255) ** (1 / gamma)) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "cloud_table = np.array([((i / 255) ** (1 / gamma2)) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "\n",
    "# Add the rain effect to each frame of your video\n",
    "while your_cap.isOpened():\n",
    "    ret, your_frame = your_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Read a frame from the rain video\n",
    "    ret, rain_frame = rain_cap.read()\n",
    "    if not ret:\n",
    "        # Restart the rain video if it reaches the end\n",
    "        rain_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, rain_frame = rain_cap.read()\n",
    "\n",
    "    ret, cloud_frame = cloud_cap.read()\n",
    "    if not ret:\n",
    "        # Restart the rain video if it reaches the end\n",
    "        cloud_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, cloud_frame = cloud_cap.read()\n",
    "\n",
    "    # Resize the rain frame to match the size of your video frame\n",
    "    rain_frame = cv2.resize(rain_frame, (width, height))\n",
    "    your_frame = cv2.resize(your_frame, (width, height))\n",
    "    cloud_frame = cv2.resize(cloud_frame, (width, height))\n",
    "    cloud_frame = cv2.cvtColor(cloud_frame, cv2.COLOR_BGR2GRAY)\n",
    "    cloud_frame = cv2.bitwise_not(cloud_frame)\n",
    "    cloud_frame = cv2.LUT(cloud_frame, cloud_table)\n",
    "\n",
    "\n",
    "    # cloud_frame = 1 - cloud_frame\n",
    "    cloud_frame = cv2.merge([cloud_frame, cloud_frame, cloud_frame])\n",
    "\n",
    "    # Add the rain effect to your video frame\n",
    "    output_frame = cv2.addWeighted(your_frame, 0.9, rain_frame, 0.9, 0)\n",
    "    output_frame = cv2.addWeighted(output_frame, 0.9, cloud_frame, 0.5, 0)\n",
    "\n",
    "    output_frame = cv2.LUT(output_frame, gamma_table)\n",
    "\n",
    "    # Write the output frame to the output video\n",
    "    out_rain.write(output_frame)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Output Video\", output_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video captures and writer\n",
    "your_cap.release()\n",
    "rain_cap.release()\n",
    "out_rain.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_track_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
